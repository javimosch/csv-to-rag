# Final LLM completion (See onlyContext)
OPENAI_MODEL=gsk_xxxx
OPENAI_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
OPENAI_MODEL_FALLBACK=meta-llama/llama-4-scout-17b-16e-instruct
OPENAI_BASE_URL=https://api.groq.com/openai/v1

LLM_SYSTEM_PROMPT="You are a helpful assistant. Use the provided context to answer questions accurately."

# Embedding
OPENAI_API_KEY=your_openai_api_key
## Priority over EMBEDDING_OPENAI_API_KEY
EMBEDDING_OPENAI_API_KEY=your_openai_api_key

## Chunking related

CSV_DELIMITER=';'


# Persistance
MONGODB_URI=your_mongodb_uri

# Vector DB
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX=your_pinecone_index
PINECONE_HOST=your_pinecone_host
## Batch Processing Configuration
### Number of vectors to process in each batch
PINECONE_BATCH_SIZE=100  
### Delay in milliseconds between batch processing (rate limiting)
PINECONE_BATCH_DELAY=100 

EMBEDDING_OPENAI_MODEL=text-embedding-ada-002-v2
EMBEDDING_OPENAI_BASE_URL=https://api.openai.com/v1

# Server related

PORT=3000

## Basic authentication
UI_USERNAME=admin
UI_PASSWORD=admin

## Backend authentication
BACKEND_API_KEY=secret_api_key